import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout, Activation
from keras.models import model_from_json
from keras.models import load_model
import matplotlib.pyplot as plt
import numpy
import time


## ************** Function for training and dumping the model  *************
def train(infile):
    numpy.random.seed(7)

    #dataset = numpy.loadtxt("../pima-indians-diabetes.csv", delimiter=",")
    dataset = numpy.loadtxt(infile+".csv", delimiter=",")

    #split data-set

    #X = dataset[:,0]
    #Y = dataset[:,1:9]
    #class label
    X = dataset[:,0]
    #fefature vectors
    Y = dataset[:,1:1809]


    #print X
    #print Y

    ## MOdel definitin

    model = Sequential()
    # using gaussian initializer to avoid multiplicative impact of weight aggregation
    # others can also be tried
    #model.add(Dense(1,input_dim=1808, init ='uniform', activation ='sigmoid'))
    model.add(Dense(1808,input_dim=1808, init ='uniform'))
    model.add(keras.layers.advanced_activations.PReLU())
    #model.add(Dropout(0.2))
    #model.add(Dense(1808,init ='uniform'))
    #model.add(keras.layers.advanced_activations.PReLU())
    model.add(Dropout(0.5))
    model.add(Dense(1,activation='sigmoid'))

    # Compile model
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

    # Fit the model
    start_train= time.time()
    history = model.fit(Y, X, validation_split=0.10, epochs=150, verbose=1)
    end_train=time.time()
    print "time elapsed in training   ",(end_train-start_train)
    #calculating time elapsed in predictions
    print(history.history.keys())

    # evaluate the model
    scores = model.evaluate(Y, X)
    print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))


    plt.plot(history.history['acc'])
    plt.plot(history.history['val_acc'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
    # summarize history for loss
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
    

def main():
    f="/home/mayank/Desktop/data/testing/neural/train_wo_size"
    train (f)

if __name__ == "__main__":
    main()
